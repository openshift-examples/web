# External ElasticSearch & Kibana with OpenShift



## Install ElasticSearch & Kibana

* https://opendistro.github.io/for-elasticsearch-docs/docs/install/rpm/
* https://opendistro.github.io/for-elasticsearch-docs/docs/kibana/

kibana: server.host: 192.168.1.106
elastic: network.host: 192.168.1.106


## DaemonSet anpassen

https://docs.openshift.com/container-platform/3.11/install_config/aggregate_logging.html#sending-logs-to-an-external-elasticsearch-instance

https://access.redhat.com/solutions/2771291


### 1) Greate your own elastic seatch storage output.

* Create basis custom output config 
** `oc rsh $(oc get pods -l component=fluentd -o name | head -1) cat /etc/fluent/configs.d/openshift/output-es-config.conf > output-custom-es-config.conf`
** `oc rsh $(oc get pods -l component=fluentd -o name | head -1) cat /etc/fluent/configs.d/openshift/output-es-ops-config.conf > output-custom-es-config.conf`

* Adjust output-custom-es-config.conf and output-custom-es-ops-config.conf, example output-custom-es-config.conf adjustment:
+
[source,diff]
----
$ diff -Nuar output-custom-es-config.conf.ORG output-custom-es-config.conf
--- output-custom-es-config.conf.ORG	2019-04-01 15:11:06.000000000 +0200
+++ output-custom-es-config.conf	2019-04-01 15:56:11.000000000 +0200
@@ -8,12 +8,12 @@
       target_index_key viaq_index_name
       id_key viaq_msg_id
       remove_keys viaq_index_name
-      user fluentd
-      password changeme
-
-      client_key "#{ENV['ES_CLIENT_KEY']}"
-      client_cert "#{ENV['ES_CLIENT_CERT']}"
-      ca_file "#{ENV['ES_CA']}"
+      user admin
+      password admin
+      ssl_verify false
+      #client_key "#{ENV['ES_CLIENT_KEY']}"
+      #client_cert "#{ENV['ES_CLIENT_CERT']}"
+      #ca_file "#{ENV['ES_CA']}"

       type_name com.redhat.viaq.common
       retry_tag "retry_es"
@@ -28,7 +28,7 @@
       max_retry_wait "#{ENV['ES_RETRY_WAIT'] || '300'}"
       disable_retry_limit true
       buffer_type file
-      buffer_path '/var/lib/fluentd/buffer-output-es-config'
+      buffer_path '/var/lib/fluentd/buffer-output-custom-es-config'
       buffer_queue_limit "#{ENV['BUFFER_QUEUE_LIMIT'] || '32' }"
       buffer_chunk_limit "#{ENV['BUFFER_SIZE_LIMIT'] || '8m' }"
       buffer_queue_full_action "#{ENV['BUFFER_QUEUE_FULL_ACTION'] || 'block'}"
----

* Add output-custom-es-config.conf to configmap/logging-fluentd `oc patch configmap/logging-fluentd -p "$(jq -n --arg es "$(cat output-custom-es-config.conf)" '{"data":{"output-custom-es-config.conf":$es}}')"`
* Add output-custom-es-ops-config.conf to configmap/logging-fluentd `oc patch configmap/logging-fluentd -p "$(jq -n --arg es "$(cat output-custom-es-ops-config.conf)" '{"data":{"output-custom-es-ops-config.conf":$es}}')"`
   

* Adjust `<label @OUTPUT` in fluent.conf at configmap/logging-fluentd file. Add match for Operations and Applications:
+
[source,diff]
----
      # Operations
      <match output_ops_tag journal.** system.var.log** mux.ops audit.log**  **_default_** **_openshift_** **_openshift-*_** **_kube-*_**>
        @type copy
        @include configs.d/user/output-custom-es-ops-config.conf
      </match>
      # Applications
      <match **>
        @type copy
        @include configs.d/user/output-custom-es-config.conf
      </match>
----

** How to get example `<match` tags:
+
[source,shell]
----
$ oc rsh $(oc get pods -l component=fluentd -o name | head -1) grep -ri '<match' /etc/fluent/configs.d/openshift/output-operations.conf /etc/fluent/configs.d/openshift/output-applications.conf
/etc/fluent/configs.d/openshift/output-operations.conf:<match retry_es_ops>
/etc/fluent/configs.d/openshift/output-operations.conf:<match output_ops_tag journal.** system.var.log** mux.ops audit.log**  **_default_** **_openshift_** **_openshift-*_** **_kube-*_**>
/etc/fluent/configs.d/openshift/output-applications.conf:<match retry_es>
/etc/fluent/configs.d/openshift/output-applications.conf:<match **>
----

### 2) Adjust daemonset/logging-fluentd enviroment variable ES_HOST & OPS_HOST

If you like to restart all pods at once: ```oc delete pods -l component=fluentd```



## Usefull ElasticSearch API/Curl commands

### Create an indice
```
curl -X PUT -u admin:admin -k "https://$ES_HOST:$ES_PORT/twitter/_doc/1" -H 'Content-Type: application/json' -d'
{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}
'
```

### List all indices
```
curl -XGET https://$ES_HOST:$ES_PORT/_cat/indices?v -u admin:admin --insecure
```

### Delete an indices
```
curl -XDELETE -s https://$ES_HOST:$ES_PORT/twitter -u admin:admin --insecure
```