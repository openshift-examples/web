apiVersion: v1
data:
  fluent.conf: |
    # This file is the fluentd configuration entrypoint. Edit with care.

    @include configs.d/openshift/system.conf

    # In each section below, pre- and post- includes don't include anything initially;
    # they exist to enable future additions to openshift conf as needed.

    ## sources
    ## ordered so that syslog always runs last...
    @include configs.d/openshift/input-pre-*.conf
    @include configs.d/dynamic/input-docker-*.conf
    @include configs.d/dynamic/input-syslog-*.conf
    @include configs.d/openshift/input-post-*.conf
    ##

    <label @INGRESS>
    ## filters
      @include configs.d/openshift/filter-pre-*.conf
      @include configs.d/openshift/filter-retag-journal.conf
      @include configs.d/openshift/filter-k8s-meta.conf
      @include configs.d/openshift/filter-kibana-transform.conf
      @include configs.d/openshift/filter-k8s-flatten-hash.conf
      @include configs.d/openshift/filter-k8s-record-transform.conf
      @include configs.d/openshift/filter-syslog-record-transform.conf
      @include configs.d/openshift/filter-viaq-data-model.conf
      @include configs.d/openshift/filter-post-*.conf
    ##
    </label>

    <label @OUTPUT>
    ## matches
      #@include configs.d/openshift/output-pre-*.conf
      #@include configs.d/openshift/output-operations.conf
      #@include configs.d/openshift/output-applications.conf
      # no post - applications.conf matches everything left
    ##
<match output_ops_tag journal.** system.var.log** mux.ops audit.log**  **_default_** **_openshift_** **_openshift-*_** **_kube-*_**>

      <match **>
        @type copy
        <store>
          @type elasticsearch
          @id elasticsearch-apps
          # 95.216.125.133
          host "#{ENV['ES_HOST']}"
          # 9200
          port "#{ENV['ES_PORT']}"
          scheme https
          ssl_version TLSv1_2
          target_index_key viaq_index_name
          id_key viaq_msg_id
          remove_keys viaq_index_name
          user admin
          password admin
          ssl_verify false
          #client_key "#{ENV['ES_CLIENT_KEY']}"
          #client_cert "#{ENV['ES_CLIENT_CERT']}"
          #ca_file "#{ENV['ES_CA']}"

          type_name com.redhat.viaq.common
          retry_tag "retry_es"

          reload_connections "#{ENV['ES_RELOAD_CONNECTIONS'] || 'true'}"
          # https://github.com/uken/fluent-plugin-elasticsearch#reload-after
          reload_after "#{ENV['ES_RELOAD_AFTER'] || '200'}"
          # https://github.com/uken/fluent-plugin-elasticsearch#sniffer-class-name
          sniffer_class_name "#{ENV['ES_SNIFFER_CLASS_NAME'] || 'Fluent::ElasticsearchSimpleSniffer'}"
          reload_on_failure false
          flush_interval "#{ENV['ES_FLUSH_INTERVAL'] || '1s'}"
          max_retry_wait "#{ENV['ES_RETRY_WAIT'] || '300'}"
          disable_retry_limit true
          buffer_type file
          buffer_path '/var/lib/fluentd/buffer-output-es-config'
          buffer_queue_limit "#{ENV['BUFFER_QUEUE_LIMIT'] || '32' }"
          buffer_chunk_limit "#{ENV['BUFFER_SIZE_LIMIT'] || '8m' }"
          buffer_queue_full_action "#{ENV['BUFFER_QUEUE_FULL_ACTION'] || 'block'}"
          flush_at_shutdown "#{ENV['FLUSH_AT_SHUTDOWN'] || 'false'}"

          write_operation 'create'

          # 2 ^ 31
          request_timeout 2147483648
        </store>
      </match>
    </label>
  secure-forward.conf: |
    # <store>
    # @type secure_forward

    # self_hostname ${hostname}
    # shared_key <SECRET_STRING>

    # secure yes
    # enable_strict_verification yes

    # ca_cert_path /etc/fluent/keys/your_ca_cert
    # ca_private_key_path /etc/fluent/keys/your_private_key
      # for private CA secret key
    # ca_private_key_passphrase passphrase

    # <server>
      # or IP
    #   host server.fqdn.example.com
    #   port 24284
    # </server>
    # <server>
      # ip address to connect
    #   host 203.0.113.8
      # specify hostlabel for FQDN verification if ipaddress is used for host
    #   hostlabel server.fqdn.example.com
    # </server>
    # </store>
  throttle-config.yaml: |
    # Logging example fluentd throttling config file

    #example-project:
    #  read_lines_limit: 10
    #
    #.operations:
    #  read_lines_limit: 100
kind: ConfigMap
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","data":{"fluent.conf":"# This file is the fluentd configuration entrypoint. Edit with care.\n\n@include configs.d/openshift/system.conf\n\n# In each section below, pre- and post- includes don't include anything initially;\n# they exist to enable future additions to openshift conf as needed.\n\n## sources\n## ordered so that syslog always runs last...\n@include configs.d/openshift/input-pre-*.conf\n@include configs.d/dynamic/input-docker-*.conf\n@include configs.d/dynamic/input-syslog-*.conf\n@include configs.d/openshift/input-post-*.conf\n##\n\n\u003clabel @INGRESS\u003e\n## filters\n  @include configs.d/openshift/filter-pre-*.conf\n  @include configs.d/openshift/filter-retag-journal.conf\n  @include configs.d/openshift/filter-k8s-meta.conf\n  @include configs.d/openshift/filter-kibana-transform.conf\n  @include configs.d/openshift/filter-k8s-flatten-hash.conf\n  @include configs.d/openshift/filter-k8s-record-transform.conf\n  @include configs.d/openshift/filter-syslog-record-transform.conf\n  @include configs.d/openshift/filter-viaq-data-model.conf\n  @include configs.d/openshift/filter-post-*.conf\n##\n\u003c/label\u003e\n\n\u003clabel @OUTPUT\u003e\n## matches\n  #@include configs.d/openshift/output-pre-*.conf\n  #@include configs.d/openshift/output-operations.conf\n  #@include configs.d/openshift/output-applications.conf\n  # no post - applications.conf matches everything left\n \u003cmatch journal.system** system.var.log** **_default_** **_openshift_** **_openshift-infra_**\u003e\n   @type elasticsearch_dynamic\n   host \"#{ENV['OPS_HOST']}\"\n   port \"#{ENV['OPS_PORT']}\"\n   scheme https\n   index_name .operations.${record['time'].nil? ? Time.at(time).getutc.strftime(@logstash_dateformat) : Time.parse(record['time']).getutc.strftime(@logstash_dateformat)}\n\n   ca_file \"#{ENV['OPS_CA']}\"\n\n   flush_interval 5s\n   max_retry_wait 300\n   disable_retry_limit\n   resurrect_after 5s\n   reload_connections false\n \u003c/match\u003e\n \u003cmatch **\u003e\n   @type elasticsearch_dynamic\n   host \"#{ENV['ES_HOST']}\"\n   port \"#{ENV['ES_PORT']}\"\n   scheme https\n   index_name ${record['kubernetes_namespace_name']}.${record['kubernetes_namespace_id']}.${Time.at(time).getutc.strftime(@logstash_dateformat)}\n\n   ca_file \"#{ENV['ES_CA']}\"\n\n   flush_interval 5s\n   max_retry_wait 300\n   disable_retry_limit\n   resurrect_after 5s\n   reload_connections false\n \u003c/match\u003e\n##\n\u003c/label\u003e\n","secure-forward.conf":"# \u003cstore\u003e\n# @type secure_forward\n\n# self_hostname ${hostname}\n# shared_key \u003cSECRET_STRING\u003e\n\n# secure yes\n# enable_strict_verification yes\n\n# ca_cert_path /etc/fluent/keys/your_ca_cert\n# ca_private_key_path /etc/fluent/keys/your_private_key\n  # for private CA secret key\n# ca_private_key_passphrase passphrase\n\n# \u003cserver\u003e\n  # or IP\n#   host server.fqdn.example.com\n#   port 24284\n# \u003c/server\u003e\n# \u003cserver\u003e\n  # ip address to connect\n#   host 203.0.113.8\n  # specify hostlabel for FQDN verification if ipaddress is used for host\n#   hostlabel server.fqdn.example.com\n# \u003c/server\u003e\n# \u003c/store\u003e\n","throttle-config.yaml":"# Logging example fluentd throttling config file\n\n#example-project:\n#  read_lines_limit: 10\n#\n#.operations:\n#  read_lines_limit: 100\n"},"kind":"ConfigMap","metadata":{"annotations":{},"creationTimestamp":null,"name":"logging-fluentd","namespace":"openshift-logging","selfLink":"/api/v1/namespaces/openshift-logging/configmaps/logging-fluentd"}}
  creationTimestamp: null
  name: logging-fluentd
  selfLink: /api/v1/namespaces/openshift-logging/configmaps/logging-fluentd
